{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "SmartRAG": "Information",
      "SmartRAG.Services": "Information",
      "SmartRAG.Services.AudioConversionService": "Information",
      "SmartRAG.Services.WhisperAudioParserService": "Information",
      "Microsoft": "Information",
      "System": "Information"
    }
  },
  "SmartRAG": {
    "MaxChunkSize": 1000,
    "MinChunkSize": 100,
    "ChunkOverlap": 200,
    "MaxRetryAttempts": 3,
    "RetryDelayMs": 1000,
    "RetryPolicy": "ExponentialBackoff",
    "EnableFallbackProviders": false,
    "MaxSearchResults": 10,
    "DefaultSystemMessage": "You are a helpful AI assistant. You analyze database queries and provide clear and understandable answers to the user.",
    "EnableAutoSchemaAnalysis": true,
    "EnablePeriodicSchemaRefresh": false,
    "WhisperConfig": {
      // Whisper Model Selection Guide:
      // - ggml-tiny.bin (75 MB): Fast, basic accuracy - For quick testing only
      // - ggml-base.bin (142 MB): Good for simple demos
      // - ggml-medium.bin (1.5 GB): Good accuracy
      // - ggml-large-v3.bin (2.9 GB): **DEFAULT** - Production-ready, best accuracy
      // 
      // Why Large-v3 as Default?
      // ✓ Superior language detection (critical for multi-language RAG)
      // ✓ Minimal hallucination (duplicate/noise filtering)
      // ✓ One-time download, lifetime accuracy benefit
      // ✓ 2.9 GB is acceptable for production systems
      // Model auto-downloads on first use from Hugging Face (~5-10 min)
      "ModelPath": "models/ggml-large-v3.bin",
      
      // Language Detection:
      // - "auto": Automatic language detection (recommended for multi-language scenarios)
      // - "en": Force English
      // - "tr": Force Turkish
      // - "de": Force German, etc. (99+ languages supported)
      "DefaultLanguage": "auto",
      
      // Quality Settings:
      // - MinConfidenceThreshold: Skip low-quality segments (0.0-1.0, default 0.3)
      // - PromptHint: Context hint for better accuracy (e.g., "Medical conversation", "Technical interview")
      // - IncludeWordTimestamps: Include detailed timing information
      // - MaxThreads: CPU threads (0 = auto-detect, use all available cores)
      "MinConfidenceThreshold": 0.3,
      "IncludeWordTimestamps": false,
      "PromptHint": "",
      "MaxThreads": 0
    }
  },
  "DatabaseConnections": [
    {
      "Name": "Database1",
      "ConnectionString": "Data Source=path/to/your/database.db",
      "DatabaseType": "SQLite",
      "Description": "Your SQLite database description",
      "Enabled": false
    },
    {
      "Name": "Database2",
      "ConnectionString": "Server=your-server,1433;Database=YourDatabase;User Id=your-user;Password=your-password;TrustServerCertificate=true;",
      "DatabaseType": "SqlServer",
      "Description": "Your SQL Server database description",
      "Enabled": false
    },
    {
      "Name": "Database3",
      "ConnectionString": "Server=your-server;Port=3306;Database=YourDatabase;User=your-user;Password=your-password;",
      "DatabaseType": "MySQL",
      "Description": "Your MySQL database description",
      "Enabled": false
    },
    {
      "Name": "Database4",
      "ConnectionString": "Server=your-server;Port=5432;Database=YourDatabase;User Id=your-user;Password=your-password;",
      "DatabaseType": "PostgreSQL",
      "Description": "Your PostgreSQL database description",
      "Enabled": false
    }
  ],
  "Storage": {
    "Redis": {
      "ConnectionString": "localhost:6379",
      "Password": "",
      "Username": "",
      "Database": 0,
      "KeyPrefix": "smartrag:local:",
      "ConnectionTimeout": 30,
      "EnableSsl": false,
      "RetryCount": 3,
      "RetryDelay": 1000
    },
    "FileSystem": {
      "FileSystemPath": "Documents"
    },
    "Sqlite": {
      "DatabasePath": "SmartRAG.db",
      "EnableForeignKeys": true,
      "ConnectionTimeout": 30
    },
    "InMemory": {
      "MaxDocuments": 1000
    },
    "Qdrant": {
      "Host": "http://localhost:6333",
      "UseHttps": false,
      "ApiKey": "",
      "CollectionName": "smartrag_local",
      "VectorSize": 768,
      "DistanceMetric": "Cosine"
    }
  },
  "AI": {
    "Custom": {
      "ApiKey": "",
      "Endpoint": "http://localhost:11434/v1/chat/completions",
      "EmbeddingEndpoint": "http://localhost:11434/api/embeddings",
      "Model": "llama3.2",
      "EmbeddingModel": "nomic-embed-text",
      "MaxTokens": 4096,
      "Temperature": 0.3
    },
    "OpenAI": {
      "ApiKey": "your-openai-api-key-here",
      "Endpoint": "https://api.openai.com/v1",
      "Model": "gpt-4o-mini",
      "EmbeddingModel": "text-embedding-3-small",
      "MaxTokens": 4096,
      "Temperature": 0.7
    },
    "Anthropic": {
      "ApiKey": "your-anthropic-api-key-here",
      "Endpoint": "https://api.anthropic.com",
      "Model": "claude-3-haiku-20240307",
      "MaxTokens": 2000,
      "Temperature": 0.3,
      "EmbeddingApiKey": "your-voyageai-api-key-here",
      "EmbeddingModel": "voyage-3.5"
    },
    "Gemini": {
      "ApiKey": "your-gemini-api-key",
      "Endpoint": "https://generativelanguage.googleapis.com/v1beta",
      "Model": "gemini-1.5-flash",
      "EmbeddingModel": "embedding-001",
      "MaxTokens": 4096,
      "Temperature": 0.3
    },
    "AzureOpenAI": {
      "ApiKey": "your-azure-openai-api-key",
      "Endpoint": "https://your-resource.openai.azure.com/",
      "Model": "gpt-4",
      "EmbeddingModel": "text-embedding-ada-002",
      "ApiVersion": "2024-10-21",
      "MaxTokens": 4096,
      "Temperature": 0.7
    }
  }
}
